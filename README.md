# Deep Learning para predecir interacciones proteÃ­na-proteÃ­na

Este proyecto corresponde al Trabajo Fin de MÃ¡ster (TFM) en Inteligencia Artificial de Santiago Martinez Willi. El objetivo principal es desarrollar modelos de aprendizaje profundo para predecir interacciones proteÃ­na-proteÃ­na (PPI) a partir de secuencias de aminoÃ¡cidos, utilizando Ãºnicamente datos pÃºblicos y tÃ©cnicas computacionales reproducibles.

## ğŸŒ± MotivaciÃ³n

Las interacciones proteÃ­na-proteÃ­na son fundamentales para el funcionamiento celular y los mecanismos de enfermedades humanas. Sin embargo, los mÃ©todos experimentales actuales para identificarlas (como Y2H o AP/MS) son costosos y presentan alta tasa de falsos positivos y negativos. Este proyecto explora el uso de redes neuronales profundas, incluyendo arquitecturas siamesas y embeddings preentrenados, como alternativa eficiente y escalable.

## ğŸ§  Modelos implementados

El proyecto evalÃºa tres modelos principales:

1. **Modelo siamÃ©s convolucional**
   - Entrada: codificaciÃ³n numÃ©rica simple con un mÃ¡ximo de longitud de secuencia de 1024
   - Arquitectura: red neuronal siamesa con convoluciones 1D
   - Accuracy: 84.72%, F1: 0.8501, ROC AUC: 0.9317

2. **Modelo basado en la arquitectura PIPR**
   - Entrada: codificaciÃ³n numÃ©rica simple con un mÃ¡ximo de longitud de secuencia de 768
   - Arquitectura: siamesa con capas residuales RCNN
   - Accuracy: 75.23%, F1: 0.7422, ROC AUC: 0.8309

3. **Modelo basado en embeddings preentrenados (ESM-2)**
   - Entrada: vectores de embedding generados con ESM-2 (t6_8M_UR50D)
   - Arquitectura: Siamese MLP
   - Accuracy: 84.36%, F1: 0.8426, ROC AUC: 0.9220

## ğŸ“Š Resultados

| Modelo                                       | Accuracy (%) | F1 Score | ROC AUC | Ã‰pocas | Tiempo por Ã©poca | Tiempo total aprox. |
|---------------------------------------------|--------------|----------|---------|--------|------------------|----------------------|
| Siamese convolucional                       | 84.72        | 0.8501   | 0.9317  | 50     | ~8 min           | ~7 h                 |
| Arquitectura PIPR (RCNN residual)           | 75.23        | 0.7422   | 0.8309  | 9      | ~80 min          | ~12 h                |
| Siamese MLP + embeddings ESM-2 (t6_8M_UR50D)| 84.36        | 0.8426   | 0.9220  | 36     | ~2 min           | ~1 h + 15 h embeddings |

## ğŸ“ Estructura del proyecto

```
TFM/
â”œâ”€â”€ notebooks/           # Notebooks Jupyter para experimentaciÃ³n y entrenamiento
â”œâ”€â”€ datasets/            # Datos originales y procesados
â”œâ”€â”€ processed_data/      # Datos transformados y embeddings
â”œâ”€â”€ models/              # Modelos entrenados y checkpoints
â”œâ”€â”€ src/                 # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ computation/     # IntegraciÃ³n con Azure ML
â”‚   â”œâ”€â”€ encoders/        # Encoders de secuencias proteicas
â”‚   â”œâ”€â”€ models/          # Arquitecturas y pipelines de entrenamiento
â”‚   â”œâ”€â”€ utils.py         # Utilidades generales
â”‚   â”œâ”€â”€ proteins_preprocessor.py
â”‚   â”œâ”€â”€ protein_dataset.py
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ requirements.txt     # Dependencias del proyecto
â”œâ”€â”€ .env                 # Variables de entorno para Azure ML
```

## ğŸ”§ InstalaciÃ³n

1. **Clona el repositorio:**
     ```bash
     git clone <url-del-repo>
     cd TFM
     ```

2. **Crea y activa un entorno virtual:**
     ```bash
     python3 -m venv tfm_env
     source tfm_env/bin/activate
     ```

3. **Instala las dependencias:**
     ```bash
     pip install -r requirements.txt
     ```

4. **Configura las variables de entorno para Azure ML si planeas usarlo:**  
     A partir del archivo `.env.example`, crea el archivo `.env` con tus credenciales y recursos de Azure.

## ğŸ“š Referencias

- Chen et al. (2019). *Siamese residual RCNN for proteinâ€“protein interaction prediction*. Bioinformatics. https://doi.org/10.1093/bioinformatics/btz328

- Spinello et al. (2022). *Deep learning approaches to protein-protein interaction prediction: a systematic review*. Frontiers in Bioinformatics. https://doi.org/10.3389/fbinf.2022.837721

- HuggingFace Transformers: [https://huggingface.co](https://huggingface.co)

- STRING: [https://string-db.org](https://string-db.org)

- Ensembl: [https://www.ensembl.org](https://www.ensembl.org)


## ğŸ“„ Licencia
Este proyecto estÃ¡ bajo licencia MIT. Uso acadÃ©mico permitido con cita adecuada.
