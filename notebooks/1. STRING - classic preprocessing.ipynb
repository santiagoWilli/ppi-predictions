{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRING - Classic preprocessing\n",
    "\n",
    "Este notebook es una primera aproximación donde se preprocesarán las interacciones físicas directas registradas en el dataset STRING y se codificarán numéricamente para en el siguiente notebook hacer el entrenamiento del modelo.\n",
    "\n",
    "Para ello, se ha descargado el dataset con interacciones físicas filtrado por la especie homo sapiens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "db_string_path = 'datasets/9606.protein.physical.links.full.v12.0.txt'\n",
    "df_string = pd.read_csv(db_string_path, sep=' ', low_memory=False)\n",
    "\n",
    "df_string.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza y preparación de datos\n",
    "El dataset de STRING que hemos descargado indica en la propia web: \"incl. distinction: direct vs. interologs\". Esto significa que se indica qué interacciones son directas o por interología. Para nuestro proyecto buscamos aquellas directas comprobadas en humanos mediante técnicas experimentales. Estas son las que tienen experimentos registrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_direct = df_string[df_string['experiments'] > 0]\n",
    "print(f\"Total de interacciones con evidencia experimental directa: {len(df_direct)}\")\n",
    "df_direct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos aquellas proteínas con interacción física directa, obtenemos el listado de proteínas únicas y nos quedamos con los pares de proteínas conocidos (estos serán nuestros casos positivos) para luego generar pares que no estén registrados (estos serán los casos negativos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos todas las proteínas únicas\n",
    "all_proteins = pd.unique(df_string[['protein1', 'protein2']].values.ravel())\n",
    "print(f\"Número de proteínas únicas: {len(all_proteins)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = set(\n",
    "    tuple(sorted([row['protein1'], row['protein2']]))\n",
    "    for _, row in df_direct.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "negative_pairs = set()\n",
    "\n",
    "while len(negative_pairs) < len(df_direct):\n",
    "    p1, p2 = random.sample(list(all_proteins), 2)\n",
    "    pair = tuple(sorted([p1, p2]))\n",
    "    if pair not in positive_pairs:\n",
    "        negative_pairs.add(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabamos de generar el set de casos negativos para nuestro modelo. Sin embargo, hay que aclarar que aquí nos encontramos ante uno de los mayores desafíos conceptuales de las PPI: los casos negativos no implica que esas dos proteínas se haya demostrado que no interactúen entre ellas, implica que su interacción no está recogida dentro del listado de interacciones conocidas. Esto nos dice que un par del set de negativos podría en realidad dar lugar a una interacción positiva si se hiciese una prueba experimental. Entonces, **asumimos que los pares \"negativos\" no es que no interactúen entre ellas, sino que desconocemos su interacción**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = pd.DataFrame(list(negative_pairs), columns=['protein1', 'protein2'])\n",
    "df_negative['label'] = 0\n",
    "\n",
    "df_positive = df_direct[['protein1', 'protein2']].copy()\n",
    "df_positive['label'] = 1\n",
    "\n",
    "df_string_balanced = pd.concat([df_positive, df_negative], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.fasta_parser\n",
    "importlib.reload(src.fasta_parser)\n",
    "\n",
    "from src.fasta_parser import FastaParser\n",
    "\n",
    "fasta_parser = FastaParser(\"datasets/Homo_sapiens.GRCh38.pep.all.fa\")\n",
    "protein_seqs = fasta_parser.to_dict()\n",
    "\n",
    "print(f\"Total de proteínas indexadas: {len(protein_seqs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (ensembl_id, seq) in enumerate(protein_seqs.items()):\n",
    "    print(f\"{ensembl_id}: {seq[:50]}...\")\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string_balanced[\"sequence1\"] = df_string_balanced[\"protein1\"].apply(\n",
    "    lambda p: protein_seqs.get(fasta_parser.extract_ensembl_id(p), None)\n",
    ")\n",
    "df_string_balanced[\"sequence2\"] = df_string_balanced[\"protein2\"].apply(\n",
    "    lambda p: protein_seqs.get(fasta_parser.extract_ensembl_id(p), None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string_balanced.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que hay 66626 NaNs en nuestro DF tras añadir las secuencias de aminoácidos. Investigamos qué ocurre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import analyze_missing_proteins\n",
    "\n",
    "analyze_missing_proteins(df_string_balanced, protein_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que el problema es que 366 proteínas del dataset de STRING no se encuentran en el archivo FASTA de Ensembl. Esto puede deberse a distintos factores, como que las proteínas hayan sido renombradas, retiradas o aún no incluídas en el fichero de Ensembl. Teniendo en cuenta que tenemos un dataset con 1.894.316 entradas, eliminar 66.626 no se considera un problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_string_balanced.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de codificar y preparar las secuencias proteicas como entrada al modelo, tenemos que determinar una longitud máxima (`max_length`) para todas ellas. Los modelos de deep learning, especialmente aquellos que trabajan con batches, requieren entradas de tamaño fijo.\n",
    "\n",
    "Para definir un `max_length` adecuado, analizaremos la distribución de longitudes de todas las secuencias de proteínas involucradas en los pares del dataset. Esto nos permitirá encontrar un equilibrio entre:\n",
    "\n",
    "- Maximizar la cobertura (evitar truncar demasiadas secuencias)\n",
    "- Minimizar el uso de memoria y el tiempo de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear copia y calcular longitudes\n",
    "df_lengths = pd.DataFrame()\n",
    "df_lengths[\"len_seq1\"] = df_string_balanced[\"sequence1\"].str.len()\n",
    "df_lengths[\"len_seq2\"] = df_string_balanced[\"sequence2\"].str.len()\n",
    "\n",
    "lengths = pd.concat([df_lengths[\"len_seq1\"], df_lengths[\"len_seq2\"]])\n",
    "\n",
    "print(lengths.describe())\n",
    "print(\"Cuantiles:\")\n",
    "print(lengths.quantile([0.5, 0.75, 0.90, 0.95, 0.99]))\n",
    "\n",
    "plt.hist(lengths, bins=100, edgecolor=\"black\")\n",
    "plt.title(\"Distribución de longitudes de secuencias\")\n",
    "plt.xlabel(\"Longitud\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.xlim(0, 2000)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El histograma muestra que la gran mayoría de las secuencias tienen una longitud inferior a 1000 aminoácidos. En concreto, los percentiles calculados reflejan que:\n",
    "\n",
    "- El 90 % de las secuencias tienen ≤ 1174 aminoácidos\n",
    "- El 95 % tienen ≤ 1622\n",
    "- El 99 % tienen ≤ 2839\n",
    "\n",
    "Basándonos en esta distribución, se ha decidido establecer un `max_length` de **1024**. Este valor permite cubrir hasta casi el 90 % de las secuencias sin truncamiento, al tiempo que mantiene un consumo de memoria razonable compatible con la GPU disponible. Las secuencias más largas serán truncadas para ajustarse a esta longitud, mientras que las más cortas serán completadas mediante padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encoders.numeric_sequence_encoder import NumericSequenceEncoder\n",
    "from src.sequence_preprocessor import SequencePreprocessor\n",
    "\n",
    "encoder = NumericSequenceEncoder()\n",
    "preprocessor = SequencePreprocessor(encoder, max_length=1024)\n",
    "\n",
    "df_encoded = preprocessor.process_dataframe(df_string_balanced)\n",
    "df_encoded.to_parquet(\"processed_data/classic_encoded_1024.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión del preprocesamiento\n",
    "\n",
    "En este primer notebook se ha llevado a cabo el preprocesamiento completo del dataset de interacciones proteína-proteína (PPI) con evidencia experimental directa, extraído de la base de datos STRING.\n",
    "\n",
    "El proceso incluyó la asociación de secuencias de aminoácidos mediante identificadores Ensembl, la codificación numérica de las secuencias con una longitud máxima de 1024 residuos, y el etiquetado binario de las interacciones (positivas y negativas). Para ello se implementaron clases reutilizables siguiendo principios de diseño limpio y modular, como `SequencePreprocessor` y `SequenceEncoder`.\n",
    "\n",
    "El resultado final es un archivo en formato `.parquet` que contiene los datos preprocesados y balanceados, listos para ser utilizados en la fase de entrenamiento del modelo de deep learning. Este enfoque desacopla el procesamiento de datos del entrenamiento, facilitando futuras pruebas con distintos modelos y codificadores sin necesidad de repetir esta etapa.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
